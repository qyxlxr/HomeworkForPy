# <center> **第三次作业：网络爬虫程序设计**</center>
## 姓名：李潇睿
## 班级：通信1604班
## 学号：41624401
## 作品说明：编写了一个爬虫，遍历了scce.ustb.edu.cn下的所有子链接（仅限scce.ustb.edu.cn域名下）并筛选出所有图片下载。
-----
## 1.库使用
### 由于我校网站相对来说比较和蔼可亲，没有设置反扒措施也没有限制访问次数，所以本次直接使用了requests请求进行爬取，然后直接使用正则表达式分析返回的html内容，serech出其中包括图片信息的部分，保存成一个URL，下载。

## 2.类使用
本项目的类快赶上大作业了，设计了一个LinkQueue队列，用来存储已爬的和未爬的信息，在队列add时对链接的合法性进行判断，结构清晰，又设计了一个Spider类，其有两个成员变量，分别是url的LinkQueue和images的LinkQuene，分别记录爬取的信息和进度，改成多线程也相当好改。
## 3.自动匹配网站编码方式
### 大多数网站使用utf-8编码，少数使用了gb2312,在request的时候使用try+Except捕获一下异常，然后用chardet.detect探测一下当前网页的编码重新request即可。

## 4.正则表达式的使用
``` 
(?<=href=").*?(?=")|(?<=href=\'). *?(?=\')
```
其中?<=这个部分是亮点，表示括号中的子模式必须出现在匹配内容的左侧，且不出现在匹配内容的结果里，相似的还有?<! 不出现，?= 右侧等。 这个老师上课没提过，但是在搜集资料的时候发现提取网页时用的很多。

## 发现的问题:有些图片最后下载失败了，打开发现是标准的response 404，怀疑是不是有一些网页在设计的时候返回头里面写的是response 200但是返回了404界面，导致程序没有进exception。